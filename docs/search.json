[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "(images/nick-byu.jpg)"
  },
  {
    "objectID": "about.html#background",
    "href": "about.html#background",
    "title": "About Me",
    "section": "Background",
    "text": "Background\nWelcome! I’m currently a senior at Brigham Young University studying Statistics and Computer Science. My obsession with analyzing how complex processess and relationships in the mathemetical sciences explain our world eventually drew me to study relevant metholodogies whose principles can be programmed, optimized, and scaled. I’ve enjoyed leveraging this knowledge to engineer solutions in accessibility, education, healthcare, marketing, and economics. My passion for continual learning enhances this expertise, and opportunities to make meaningful contributions in these areas and others always excites me."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About Me",
    "section": "Education",
    "text": "Education\n\nBrigham Young University\n\nB.S. in Statistics & Computer Science — 2026\n\nMinor: Mathematics\n\n\nRelevant Coursework: Probability & Inference 2, Software Design, Statistical Modeling 2, Algorithm Design & Analysis, Machine Learning Operations (MLOps), Advanced Software Construction, Multivariable Calculus, Mathematics of Data Science"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "About Me",
    "section": "Experience",
    "text": "Experience\n\nProfessional Work\n\nResearch Assitant - Record Linking Lab\n\nDesigned and implemented a scalable microservice in Python using AWS server technology, automating relevant data indexing and facilitating record linking processes.\nDevised a hierarchical clustering machine learning model for enhanced identification of duplicate data, reducing record preprocessing time and improving data accuracy\nEngaged in cross-functional collaboration to orchestrate planning, development, and integration of actionable items.\n\nQA & Automation Intern - Illuminating Software\n\nFormulated and integrated automated test scripts with C# and Selenium, enhancing performance and functionality testing under test-driven development principles, facilitating error detection by 35%.\nConducted comprehensive manual and automated QA analysis to ensure reliable and robustness prior to deployment.\nDiagnosed and resolved critical technical issues within the development codebase, contributing to the development of new testing utilities.\n\n\n\n\nProjects\n\nGenerative ASL\n\nAn ongoing project to help make web content more accessible to the ASL communinity. The process has consisted of architecting a cloud pipeline that receives text transcriptions as input data and converts the transcriptions to ASL gloss. The gloss generations are then mapped to avatar pose estimations to create a 3D avatar that performs ASL overlaid onto the original video or audio content.\n\nAnnual U.S. Healthcare cost anaylsis\n\nAn in-depth analysis of U.S. Healthcare costs across households using survey panel data in an effort to discover important factors"
  },
  {
    "objectID": "about.html#skills-interests",
    "href": "about.html#skills-interests",
    "title": "About Me",
    "section": "Skills & Interests",
    "text": "Skills & Interests\n\nTechnical Skills\n\nProgramming: C#, C++, Python, Java, TypeScript, R\nData Analysis: Pandas, NumPy\nVisualization: Matplotlib, Seaborn, GGPlot2\nMachine Learning: Scikit-learn\nDeep Learning: Tensorflow, PyTorch\nTools: Jupyter, AWS, GCP\n\n\n\nAreas of Interest\n\nEconomic sector & industry performance\nFinancial fraud detection\nU.S. Healthcare expenditures\nCloud computing\nElectrocardiology research"
  },
  {
    "objectID": "about.html#get-to-know-me",
    "href": "about.html#get-to-know-me",
    "title": "About Me",
    "section": "Get to know me",
    "text": "Get to know me\n\nIn my spare time, I enjoy everything the outdoors has to offer, particularly fishing, hiking, and running. When finances permit, I am always fascinated by the"
  },
  {
    "objectID": "about.html#contact",
    "href": "about.html#contact",
    "title": "About Me",
    "section": "Contact",
    "text": "Contact\n\nEmail: nickademic@gmail.com\nGitHub: github.com/nraustin\nLinkedIn: linkedin.com/in/nick-austin-bb4b23234"
  },
  {
    "objectID": "projects/final-project.html",
    "href": "projects/final-project.html",
    "title": "Final Project",
    "section": "",
    "text": "This is coming down the pipeline. Check again later.",
    "crumbs": [
      "Final Project"
    ]
  },
  {
    "objectID": "projects/data-acquisition.html",
    "href": "projects/data-acquisition.html",
    "title": "Data Acquisition Project",
    "section": "",
    "text": "This is coming down the pipeline. Check again later.",
    "crumbs": [
      "Data Acquisition Project"
    ]
  },
  {
    "objectID": "projects/eda.html",
    "href": "projects/eda.html",
    "title": "EDA Project",
    "section": "",
    "text": "This is coming down the pipeline. Check again later.",
    "crumbs": [
      "EDA Project"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to My Data Science Portfolio",
    "section": "",
    "text": "Welcome to my data science portfolio! This site shows my journey learning data science and analytics. Here you’ll find projects that demonstrate what I’ve learned and discovered.\n\n\nThis portfolio shows my work learning data science. Each project includes:\n\nMy code with documentation\nVisualizations I created\nWhat I learned and discovered\n\nI built this site using Quarto and host it on GitHub Pages.\n\n\n\n\nProgramming: Python, Pandas for data analysis\nVisualization: Creating charts with Matplotlib and Seaborn\nData Collection: Getting data from files, websites, and APIs\nAnalysis: Finding patterns and answering questions with data\n\n\n\n\n\n\n\nLearn how I explore datasets to find interesting patterns and answer questions.\n\n\n\nSee how I gather data from different sources and prepare it for analysis.\n\n\n\nSee how I tackle a data science project beginning to end.\n\n\n\nThanks for visiting! Feel free to explore my projects and see what I’m learning."
  },
  {
    "objectID": "index.html#about-this-portfolio",
    "href": "index.html#about-this-portfolio",
    "title": "Welcome to My Data Science Portfolio",
    "section": "",
    "text": "This portfolio shows my work learning data science. Each project includes:\n\nMy code with documentation\nVisualizations I created\nWhat I learned and discovered\n\nI built this site using Quarto and host it on GitHub Pages."
  },
  {
    "objectID": "index.html#skills-im-learning",
    "href": "index.html#skills-im-learning",
    "title": "Welcome to My Data Science Portfolio",
    "section": "",
    "text": "Programming: Python, Pandas for data analysis\nVisualization: Creating charts with Matplotlib and Seaborn\nData Collection: Getting data from files, websites, and APIs\nAnalysis: Finding patterns and answering questions with data"
  },
  {
    "objectID": "index.html#my-projects",
    "href": "index.html#my-projects",
    "title": "Welcome to My Data Science Portfolio",
    "section": "",
    "text": "Learn how I explore datasets to find interesting patterns and answer questions.\n\n\n\nSee how I gather data from different sources and prepare it for analysis.\n\n\n\nSee how I tackle a data science project beginning to end.\n\n\n\nThanks for visiting! Feel free to explore my projects and see what I’m learning."
  }
]